
%% build: latexmk -pdf -pvc paper.tex

\documentclass[acmsmall,screen,review,anonymous]{acmart}
%% \documentclass[nonacm,acmsmall,review]{acmart}
%% \raggedbottom

%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


%% \setcopyright{rightsretained}
%% \acmPrice{}
%% \acmDOI{10.1145/3547641}
%% \acmYear{2022}
%% \copyrightyear{2022}
%% \acmSubmissionID{icfp22main-p52-p}
%% \acmJournal{PACMPL}
%% \acmVolume{6}
%% \acmNumber{ICFP}
%% \acmArticle{110}
%% \acmMonth{8}

%% These commands are for a JOURNAL article.

%% \acmJournal{JACM}
%% \acmVolume{37}
%% \acmNumber{4}
%% \acmArticle{111}
%% \acmMonth{8}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

\bibliographystyle{ACM-Reference-Format}
%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
\citestyle{acmauthoryear}

%% --------------------------------------------------------------------------------

\usepackage{xcolor}
\usepackage{mathpartir}
\usepackage{todonotes}
\presetkeys{todonotes}{inline}{}
\usepackage{scalerel}
\usepackage{bm}
\usepackage{mathtools}
%% \usepackage{amssymb}


\newcommand{\mit}[1]{\mathit{#1}}
\newcommand{\msf}[1]{\mathsf{#1}}
\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\wh}[1]{\widehat{#1}}
\newcommand{\mdo}{\mbf{do}\,}
\newcommand{\ind}{\hspace{1em}}
\newcommand{\bif}{\mbf{if}\,}
\newcommand{\bthen}{\mbf{then}\,}
\newcommand{\belse}{\mbf{else}\,}
\newcommand{\return}{\msf{return}\,}
\newcommand{\lam}{\lambda\,}
\newcommand{\data}{\mbf{data}\,}
\newcommand{\where}{\mbf{where}}
\newcommand{\M}{\msf{M}}
\newcommand{\letrec}{\mbf{letrec}\,}
\newcommand{\of}{\mbf{of}\,}
\newcommand{\go}{\mit{go}}
\newcommand{\add}{\mit{add}}
\newcommand{\letdef}{\mbf{let\,}}


\newcommand{\ext}{\triangleright}

\newcommand{\Int}{\msf{Int}}
\newcommand{\List}{\msf{List}}
\newcommand{\Nil}{\msf{Nil}}
\newcommand{\Cons}{\msf{Cons}}
\newcommand{\Reader}{\msf{Reader}}
\newcommand{\Monad}{\msf{Monad}}
\newcommand{\class}{\msf{class}}
\newcommand{\Functor}{\msf{Functor}}
\newcommand{\Bool}{\msf{Bool}}
\newcommand{\Statel}{\msf{State}}
\newcommand{\fro}{\leftarrow}
\newcommand{\case}{\mbf{case\,}}

\newcommand{\Lift}{{\Uparrow}}
\newcommand{\spl}{{\sim}}
\newcommand{\ql}{{\langle}}
\newcommand{\qr}{{\rangle}}
\newcommand{\bind}{\mathbin{>\!\!>\mkern-6.7mu=}}

\newcommand{\MTy}{\msf{MetaTy}}
\newcommand{\VTy}{\msf{ValTy}}
\newcommand{\Ty}{\msf{Ty}}
\newcommand{\CTy}{\msf{CompTy}}
\newcommand{\True}{\msf{True}}
\newcommand{\False}{\msf{False}}
\newcommand{\fst}{\msf{fst}}
\newcommand{\snd}{\msf{snd}}

\newcommand{\blank}{{\mathord{\hspace{1pt}\text{--}\hspace{1pt}}}}

\newcommand{\Nat}{\msf{Nat}}
\newcommand{\Zero}{\msf{Zero}}
\newcommand{\Suc}{\msf{Suc}}

%% \newcommand{\spl}{{\sim}}
%% \newcommand{\qut}[1]{\langle #1\rangle}

%% \newcommand{\mbbc}{\mbb{C}}
%% \newcommand{\mbbo}{\mbb{O}}
%% \newcommand{\ob}{_\mbbo}

%% \newcommand{\U}{\msf{U}}
%% \newcommand{\Con}{\msf{Con}}
%% \newcommand{\Sub}{\msf{Sub}}
%% \newcommand{\Ty}{\msf{Ty}}
%% \newcommand{\Tm}{\msf{Tm}}
%% \newcommand{\Cono}{\msf{Con}_{\mbbo}}
%% \newcommand{\Subo}{\msf{Sub}_{\mbbo}}
%% \newcommand{\Tyo}{\msf{Ty}_{\mbbo}}
%% \newcommand{\Tmo}{\msf{Tm}_{\mbbo}}
%% \newcommand{\hCon}{\wh{\msf{Con}}}
%% \newcommand{\hSub}{\wh{\msf{Sub}}}
%% \newcommand{\hTy}{\wh{\msf{Ty}}}
%% \newcommand{\hTm}{\wh{\msf{Tm}}}

%% \newcommand{\p}{\mathsf{p}}
%% \newcommand{\q}{\mathsf{q}}

%% \newcommand{\refl}{\msf{refl}}
%% \newcommand{\Bool}{\msf{Bool}}
%% \newcommand{\true}{\msf{true}}
%% \newcommand{\false}{\msf{false}}
%% \newcommand{\True}{\msf{True}}
%% \newcommand{\False}{\msf{False}}
%% \newcommand{\List}{\msf{List}}
%% \newcommand{\nil}{\msf{nil}}
%% \newcommand{\cons}{\msf{cons}}

%% \renewcommand{\tt}{\msf{tt}}
%% \newcommand{\fst}{\msf{fst}}
%% \newcommand{\snd}{\msf{snd}}
%% \newcommand{\mylet}{\msf{let}}
%% \newcommand{\emptycon}{\scaleobj{.75}\bullet}
%% \newcommand{\id}{\msf{id}}

%% \newcommand{\Set}{\mathsf{Set}}
%% \newcommand{\Prop}{\mathsf{Prop}}
%% \newcommand{\Rep}{\msf{Rep}}

%% \newcommand{\emb}[1]{\ulcorner#1\urcorner}

%% \newcommand{\Stage}{\msf{Stage}}
%% \newcommand{\hato}{\bm\hat{\mbbo}}
%% \newcommand{\ev}{\mbb{E}}
%% \newcommand{\re}{\mbb{R}}

%% \theoremstyle{remark}
%% \newtheorem{notation}{Notation}

%% \newcommand{\whset}{\wh{\Set}}
%% \newcommand{\rexti}{\re_{\ext_1}^{-1}}
%% \newcommand{\rextizero}{\re_{\ext_0}^{-1}}

%% \newcommand{\rel}{^{\approx}}
%% \newcommand{\yon}{\msf{y}}


%% --------------------------------------------------------------------------------

%%
%% end of the preamble, start of the body of the document source.
%% \hypersetup{draft}
\begin{document}

\title{Closure-Free Functional Programming in a Two-Level Type Theory}
%% \titlenote{}

%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{András Kovács}
\email{andrask@chalmers.se}
\orcid{0000-0002-6375-9781}
\affiliation{%
  \institution{University of Gothenburg}
  \country{Sweden}
  \city{Gothenburg}
}

\begin{abstract}
There are many abstraction tools in modern functional programming which heavily
rely on general-purpose compiler optimization to achieve adequate
performance. For example, monadic binding is a higher-order function which
yields runtime closures in the absence of sufficient compile-time inlining and
beta-reductions, thereby significantly degrading performance. In current systems
such as the Glasgow Haskell Compiler, there is no strong guarantee that
general-purpose optimization can eliminate abstraction overheads, and users only
have indirect and fragile control over code generation through inlining
directives and compiler options. In this paper we propose using a two-stage
language to simultaneously get strong code generation guarantees and strong
abstraction features. The object language is a simply typed first-order language
where all function calls are statically known, and which can be compiled without
runtime closures. The compile-time language is a dependent type theory. The two
are integrated in a two-level type theory. We develop some abstraction
tools in this setting. First, we develop monads and monad transformers. Second,
we develop fusion for push and pull streams. Most of our results are also
adapted to a proof-of-concept library in typed Template Haskell.
\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003752.10003790.10011740</concept_id>
       <concept_desc>Theory of computation~Type theory</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10011007.10011006.10011041.10011047</concept_id>
       <concept_desc>Software and its engineering~Source code generation</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Type theory}
\ccsdesc[500]{Software and its engineering~Source code generation}

\keywords{two-level type theory, staged compilation}

\maketitle


\section{Introduction}\label{sec:introduction}

Modern functional programming supports many convenient abstractions. These often
come with significant runtime overheads. Sometimes the overheads are acceptable,
but in other cases compiler optimization is crucial. Monads in Haskell is an
example for the latter. Even the $\Reader$ monad, which is one of the simplest
in terms of implementation, yields large overheads when compiled without
optimizations. Consider the following snippet.
\begin{alignat*}{3}
  &f :: \Int \to \Reader\,\Bool\,\Int \\
  &f\,x = \mdo\{b \fro \msf{ask}; \bif x\, \bthen \return (x + 10)\, \belse \return (x + 20)\}
\end{alignat*}
With optimizations enabled, GHC compiles this roughly to the following:
\begin{alignat*}{3}
  &f :: \Int \to \Bool \to \Int \\
  &f = \lam x\,b.\, \bif b\, \bthen x + 10\, \belse x + 20
\end{alignat*}
Without optimizations we roughly get:
\begin{alignat*}{3}
  &f = \lam x.\,(\bind)\,\msf{MonadReaderDict}\,\msf{ask}\,(\lam b.\,\bif b\\
  &\ind \bthen\return\,\msf{MonadReaderDict}\,(x + 10)\\
  &\ind \belse\hspace{0.25em}\return\,\msf{MonadReaderDict}\,(x + 20))
\end{alignat*}
Here, $\msf{MonadReaderDict}$ is a runtime dictionary, containing the methods of
the $\Monad$ instance for $\Reader$, and $(\bind)\,\msf{MonadReaderDict}$ is a
field projection. Here, a runtime closure will be created for the $\lam b.\,...$
function, and $(\bind)$, $\msf{ask}$ and $\return$ will create additional dynamic
closures.

The difference between optimized and unoptimized code is already large here, and
it gets even larger when we consider monad transformers or code that is
polymorphic over monads. In Haskell, such code is pervasive, even in fairly
basic programs which do not use fancy abstractions. The $\msf{mapM}$ function in
the Haskell Prelude, which maps over a list in some monad, is a third-order and
second-rank polymorphic function in disguise, because its monad dictionary
argument contains the polymorphic second-order $(\bind)$ method.
\begin{alignat*}{3}
  & \msf{mapM} :: \Monad\,m \Rightarrow (a \to m\,b) \to [a] \to m\,[b]
\end{alignat*}
Compiling $\msf{mapM}$ efficiently relies on inlining the instance dictionary,
then inlining the methods contained there, and also inlining the functions
that the higher-order binding method is applied to.

GHC's optimization efforts are respectable, and it has gotten quite good over
its long history of development. However, there is no strong guarantee that
certain optimizations will happen. Control over optimizations remains tricky,
fragile and non-compositional. \texttt{INLINE} and \texttt{REWRITE} pragmas can
be used to control code generation, but without any strong guarantee, and their
sophisticated usage requires knowledge of GHC internals. For example, correctly
specifying the \emph{ordering} of certain rule applications is often needed. We
have to also care about function arities. Infamously, the function composition
operator is defined as $(.)\,f\,g = \lam x \to f\,(g\,x)$ in the base libraries,
instead of as $(.)\,f\,g\,x = f\,(g\,x)$, to get better inlining behavior ---
as explained in a source comment right next to the definition \cite{TODO}.

Although there are numerous tricks and idioms that are used in high-performance
Haskell programming, for reliable performance it is necessary that programmers
periodically \emph{review} GHC's optimized code output. Needless to say, this is
rather time-consuming and poorly scalable.

\subsection{Staged Compilation}

In this paper we use staged compilation to address issues of robustness. The
idea is to shift as much as possible work from general-purpose optimization to
metaprograms.

Metaprograms can be deterministic, transparent, and can be run efficiently,
using fast interpreters or machine code compilation. In contrast,
general-purpose optimizers are slower to run, less transparent and less
reliable. Also, metaprogramming allows \emph{library authors} to exploit domain
specific optimizations, while it is not realistic for general-purpose optimizers
to know about all domains.

On the other hand, metaprogramming requires some additional care and input from
programmers. Historically, there have been problems with ergonomics as well:
\begin{itemize}
\item Code generation might fail \emph{too late} in the pipeline, producing
      incomprehensible errors; this is often caused by not having enough static
      guarantees about the well-formedness of code output.
\item Tooling for the object language (debugging, profiling, IDE support) often does not
      work for metaprogramming. This is more likely if the object and meta layers are wildly
      different.
\item Metaprogramming may introduce heavy noise and boilerplate, obscuring the logic of
      programs, or impose restrictions on how code can be structured. For instance,
      Template Haskell mandates that metaprograms used in splices in some module are
      defined in a different module.
\end{itemize}

The idea of \textbf{two-level type theory} (2LTT) is to use a highly expressive
dependent type theory for compile-time computation, but generate code in
possibly different, simpler object language. In this paper, we use 2LTT to sweeten the
deal of staged compilation, aiming for a combination of strong guarantees, good
ergonomics, high level of abstraction and easy-to-optimize code output.

We develop a particular two-level type theory for this purpose, which we
call \textbf{CFTT}, short for ``closure-free type theory''. This consists
of
\begin{itemize}
\item A simply-typed object theory with first-order functions, general recursion and
      finitary algebraic data types. This language is easy to optimize and compile
      downstream in the pipeline, but it lacks many convenience features.
\item A standard Martin-Löf type theory for the compile-time language. This
      allows us to recover many features by metaprogramming.
\end{itemize}

In particular, since the object language is first-order, we guarantee that all
programs in CFTT can be ultimately compiled without any dynamic closures, using
only calls and jumps to statically known code locations. Why focus on closures?
They are the foundation to almost all abstraction tools in functional
programming:
\begin{itemize}
\item Higher-order functions in essentially all functional languages are implemented with closures.
\item Type classes in Haskell use dictionary-passing, which relies on closures for function methods.
\item Functors and first-class modules in OCaml and other ML-s rely on closures.
\end{itemize}
Hence, doing functional programming without closures is a clear demonstration
that we can get rid of abstraction overheads.

It turns out that surprisingly little practical programming relies essentially
on closures. Most of the time, programmers use higher-order functions for
\emph{abstraction}, such as when mapping over lists, where it is expected that
the mapping function will be inlined. In other cases, the use of closures can be
eliminated by small-scale defunctionalization. For example, difference lists
\cite{TODO} are often implemented with closures, but they can be also
implemented as binary trees, with the same programming interface.

\todo{Essential closures: CPS? Threaded interpreters?}

Whole-program defunctionalization is also possible, and it is notably used by
the MLton compiler \cite{TODO}. While this can be practical and effective, it
can be also expensive and require whole-program processing. Also, conceptually
speaking, it does not eliminate closures but instead makes them more transparent
to optimizations. In this paper we do not use defunctionalization.

We note though that our setup is compatible with closures as well, and it can
support two separate type formers for closure-based and non-closure-based
(``static'') functions. Having both of these would be desirable in a practical
system. In the current work we focus on the closure-free case because it is much
less known and developed, and it is quite interesting to see how far we
can go with it.

\subsection{Contributions}

\todo{CONTRIBUTIONS}


\section{Basics of CFTT}\label{sec:basics-of-cftt}

In the following we give an overview of CFTT features. Here we focus on examples
and informal explanations. We defer the more formal details to Sections
\ref{TODO} and \ref{TODO}. We first review the meta-level language, then the
object-level one, and finally the staging operations which bridge between the
two.

\subsection{The Meta Level}\label{sec:the-meta-level}

$\bs{\MTy}$ is the universe of types in the compile-time language. We will often
use the term ``metatype'' to refer to inhabitants of $\MTy$, and use
``metaprogram'' for inhabitants of metatypes. $\MTy$ supports dependent
functions, products and indexed inductive types \cite{TODO}.

Formally, $\MTy$ is additionally indexed by universes levels, and we have
$\MTy_i : \MTy_{i+1}$. However, this adds a bit of noise, and it is not very
relevant to the current paper, so we shall omit levels. Note that universe
levels have nothing to do with staging in the sense of staged compilation; they
are about sizing for the purpose of logical consistency.

We use Agda-style syntax and implicit arguments. A basic example:
\begin{alignat*}{3}
  &id : \{A : \MTy\} \to A \to A\\
  &id = \lam x.\, x
\end{alignat*}
Here, the type argument is implicit, and it gets inferred when we use the
function. For example, $id\,\True$ is elaborated to $id\,\{\Bool\}\,\True$,
where the braces mark an explicit application for the implicit argument.
Similarly, we can introduce implicit lambdas explicitly:
\begin{alignat*}{3}
  &id = \lam \{A : \MTy\}(x : A).\,x
\end{alignat*}
We write $(a : A) \times B$ for $\Sigma$-types in $\MTy$. For the field
projections, for $t : (a : A) \times B$, we have $\fst\,t : A$ and $\snd\,t :
B[a \mapsto \fst\,t]$, and pairing is written simply as $(t,\,u)$. Additionally,
we use syntactic sugar for field projections: we can write a type as $(field_1 :
A) \times (field_2 : B) \times (field_3 : C)$, and write $t.field_2$ for a named
field projection. The type itself denotes a right-nested $\Sigma$-type. We can
also write $(t,\,u,\,v)$ for a right-nested iterated pairing. In Haskell style,
we write $()$ for the unit type, and also for its inhabitant.

Inductive types can be introduced using a Haskell-like ADT notation, or with a GADT-style one:
\begin{alignat*}{3}
  &                                           &&\hspace{4em}\data\,\Bool_\M &&: \MTy\,\where\\
  & \data\,\Bool_\M : \MTy = \True\,|\,\False &&\hspace{4em}\ind\ind \True &&: \Bool_\M\\
  &                                           &&\hspace{4em}\ind\ind \False &&: \Bool_\M
\end{alignat*}
Note that we added an $_\M$ subscript to the type; when analogous types can be
defined both on the meta and object levels, we will use this subscript to
distinguish the meta-level version.

\subsection{The Object Level}\label{sec:the-object-level}

$\bs{\Ty}$ is the universe of types in the object language. It is itself a
metatype, so so we have $\Ty : \MTy$. It is further split to two sub-universes.

First, $\bs{\VTy} : \MTy$ is the universe of \emph{value types}. $\VTy$ supports
parameterized algebraic data types, with two restrictions:
\begin{itemize}
\item ADTs can be only parameterized over types in $\VTy$.
\item Constructor fields must be in $\VTy$.
\end{itemize}
Since $\VTy$ is a sub-universe of $\Ty$, we have that when $A : \VTy$ then also
$A : \Ty$. Formally, this is specified as an explicit embedding operation but
informally it is nicer to have an implicit subtyping.

Second, $\bs{\CTy} : \MTy$ is the universe of \emph{computation types}. This is
also a sub-universe of $\Ty$ with implicit coercions. For now, we only specify
that $\CTy$ contains functions whose domain is a value type:
\[ \blank\to\blank : \VTy \to \Ty \to \CTy \]
For instance, if $\Bool : \VTy$ is defined as an object-level ADT, then $\Bool
\to \Bool : \CTy$, hence also $\Bool \to \Bool : \Ty$. However, $(\Bool \to
\Bool) \to \Bool$ is ill-formed, since the domain is not a value type. An
example for an object-level program, where we already have natural numbers
declared as $\data \Nat : \VTy := \Zero\,|\,\Suc\,\Nat$:
\begin{alignat*}{3}
  &\rlap{$\add : \Nat \to \Nat \to \Nat$}\\
  &\add :=\,&& \mathrlap{\letrec \go := \lam n\,m.\,\case n\,\of}\\
  &         && \ind \Zero   &&\to m;\\
  &         && \ind \Suc\,n &&\to \Suc\,(\go\,n\,m);\\
  &         && \go
\end{alignat*}
Every recursive definition must be introduced with $\letrec$. Note also the
single semicolon after the $\mbf{case}$ branches. The general syntax is $\letrec x :=
t; u$, optionally with a type annotation for $x$ on a separate line.

Also note that object-level definitions use $:=$ instead of $=$ for meta-level
ones. Generally, let-definitions are the biggest source of stage ambiguity in
surface notation. Later on, we will use more implicit staging notation, but we
will always disambiguate the stages of $\mbf{let}$-s in this way. Non-recursive
$\mbf{let}$ is also allowed, and can be used to shadow binders:
\begin{alignat*}{3}
  &f : \Nat \to \Nat\\
  &f := \lam x.\,\letdef x := x + 10; \letdef x := x + 20; x * 10
\end{alignat*}
$\mbf{let}$-definitions can be used to define values of any type, and the type
of the $\mbf{let}$ body can be also anything. Additionally, the right hand sides
of $\case$ branches can also have arbitrary types. So the following is
well-formed:
\begin{alignat*}{3}
  &f : \mathrlap{\Bool \to \Nat \to \Nat}\\
  &f \mathrlap{:= \lam b.\,\case b\,\of}\\
  &\ind \True  &&\to \lam x.\, x + 10;\\
  &\ind \False &&\to \lam x.\, x * 10;
\end{alignat*}
Let us discuss the object language. First, notice that there is no polymorphism
or any kind of type dependency. Although we can define lists as $\data \List\,A
: \VTy := \Nil\,|\,\Cons\,A\,(\List\,A)$, the parameterization is just a
shorthand; all concrete instantiations of the type are distinct. This
monomorphism makes it easy to use different memory layouts for different types.
For example, types which look like products may be unboxed. We could also make a
distinction between boxed and unboxed sum types. We do not explore this in
detail, we just note that monomorphic types make it easy to control memory
layouts, and we believe that this is an important part of performance
optimization.

Second, there are no higher-order functions, and functions also cannot be stored
in data structures. Hence, locally defined functions can never escape their
scope, and all function calls are to functions defined in the current
scope. This makes it possible to run object programs without using dynamic
closures. This latter point might not be completely straightforward; what
about the previous $f$ function which has $\lambda$-expressions under a
$\mbf{case}$, should that require closures?

We say that it should not. We make this formal formal in Section \ref{TODO};
here we only give an intuitive explanation. In short, we choose a call-by-name
semantics for functions, which means that the only way we can compute with a
function is by applying it to all arguments and extracting the resulting value.
Hence, the only way to compute with $f$ is to apply it to \emph{two} arguments,
so $f$ is operationally equivalent to the following definition:
\[ \lam b\,x.\,\case b\,\of \True \to x + 10; \False \to x * 10 \]
In Section \ref{TODO} we show that all object programs can be transformed to a
\emph{saturated} form, where the arity of every function call matches the number
of topmost $\lambda$-binders in the function definition.

Why not just make the object language less liberal, e.g.\ by disallowing
$\lambda$ under $\mbf{case}$ or $\mbf{let}$, thereby making call saturation
easier or more obvious? There is a trade-off between making the object language
more restricted, and thus easier to compile, and making \emph{metaprogramming}
more convenient for the object language. We will see that the ability to insert
$\mbf{let}$-s without restriction is very convenient in code generation, and
likewise the ability to have arbitrary object expressions in $\mbf{case}$
bodies. In this paper we choose to go with the most liberal object syntax, at
the cost of needing more downstream processing. The call-by-name nature of
computation types requires a bit of a change of thinking from programmers, but
we believe that it is well worth to have it for the metaprogramming convenience.

On the other side of the spectrum, one might imagine generating object code in
low-level A-normal form. This is more laborious, but it could be also
interesting, because it forces us to invent abstractions for manipulating ANF in
the metalanguage. In a similar vein, Allais recently proposed metaprogramming
quantum circuits in a two-level type theory \cite{TODO}. We leave such setups
with low-level object languages to future investigation.

Finally, one might compare our object language to call-by-push-value
(CBPV). Indeed, we took inspiration from CBPV, and there are similarities, but
also differences. In both systems there is a value-computation distinction, and
values are call-by-value, and computations are call-by-name. However, our object
language allows variable binding at arbitrary types, while CBPV only supports it
at value types. In CBPV, a let-definition for a function is only possible by
first packing it up in a closure value, which clearly does not work for us.
Also, CBPV makes a judgment-level structural distinction between values and
computations, while we use type universes for that. Generally speaking,
type-based restrictions are easier to work with in dependent type theories than
structural restrictions.


\section{TODOS}

\todo{extend as I have more stuff}
\todo{FIGURE OUT: monadic tailrec}
\todo{FIGURE OUT: Traversals}
\todo{DEVELOP: mutual letrec based on computational product types}


\section{The Object Language}\label{sec:the-object-language}

Describe object language. Simple types + first-order fun + fixpoints + ADT-s.

Show Agda formalization basically, types and syntax.

Show Agda definitional interpreter. Discuss closure-free evaluation

Examples, properties. Maybe big-step reduction? Maybe program equivalence?  Look
at Harper PFPL for program equivalence reference.

Sketch downstream compilation.
\begin{itemize}
\item Eta-expand function definitions to arity.
\item Turn functions in immediate beta-redexes to let-bindings.
\item Lambda-lift non-tail-called functions to top.
\item Keep only-tail-called local functions as join points.
\end{itemize}

Downstream compilation should erase the unit type and implement products as
``flat'' unboxed structures.

Discuss object language design choices.
\begin{itemize}
\item Can be more obviously first-order: e.g.\ no currying, only Val->Val
  functions, or ANF functions. This requires more bureaucracy in
  metaprogramming.
\item Can be more flexible but less obviously first-order: allow function let
  bodies, allow function case bodies. Requires more translation. More convenient
  to program in. In future work.
\end{itemize}

\section{The Staged Language}\label{sec:the-staged-language}

Don't give horizontal-bar rules.

Meta-features:
\begin{itemize}
\item Pi, Sigma, Unit, Bottom, Universes (indices elided), ADT-s. Ind families probably not needed.
\item Agda notation.
\item Type classes informally in Haskell notation?
\end{itemize}

Explain staging ops, staging algorithm. Explain object embedding. Refer to 2LTT
paper for correctness.

Mention stage annotation inference, but we'll not use it often! To make things
explicit.

We should include a generous amount of staging examples, and some traced staging.

Basic staging examples: identity, map, power function. Boolean short-circuiting.

Basic staged classes, Eq, Ord, Show, Monoid, etc. Vectors with computed length.

\section{Programming With Monads}\label{sec:programming-with-monads}

\subsection{Basic Binding Time Improvements}\label{sec:basic-binding-time-improvements}

Notion.
For functions.
For products.
Note that for products there is a computation duplication problem.
Mention let-insertion.

\subsection{The Code Generation Monad}\label{sec:the-code-generation-monad}

Is fundamental to this work.

Definition. Explanation. Define Functor, Applicative, Monad instances.
Define runGen, runGen1, runGenN etc. Define let-insertion.

Basic examples.

Explanation in terms of Church-coding.

Gen Vector mapping or folding example from 2LTT repo. Without Gen, it's a
big pain to get ideal linear-size map code in N. With Gen it's easy-peasy.

\subsection{Monad Transformers}\label{sec:monad-transformers}

Identity, ReaderT, StateT, MaybeT, ExceptT

Strict versions of put, modify, local, runner functions.

MTL-style overloading. MonadReader, MonadState, MonadError, MonadGen, liftGen

Binding time improvement for monads. Up/down overloading.

\subsection{Case Splitting in MonadGen}\label{sec:case-splitting-in-monadgen}

It works for any object ADT.

Introduce sums-of-values (SOV).

Introduce syntax sugar for object case splits in MonadGen blocks.

Basic examples.

\subsection{Joining Control Flow}\label{sec:rejoining-control-flow}

The problem of join points. Motivation in terms of MaybeT Gen.

We can let-bind computations by tripping through up/down of monads,
but that introduces unbox/rebox cost for Maybe \& Either.

Works OK for Reader/State though.

\begin{verbatim}
f : Bool -> MaybeT0 Gen ^Int
f = \b. ~(down do
  x <- case <b> of
    True  -> gen <10>
    False -> gen <20>
  y <- gen <~x + 10>
  z <- gen <~x * 10>
  pure <~x + ~y + ~z>)
\end{verbatim}

Join points using SOV-s. Description of SOV machinery. MonadJoin.
instance MonadJoin Gen. MonadJoin MaybeT.

\subsection{Monadic Tail Recursion}\label{sec:monadic-tail-recursion}

\texttt{replicateM\_}, \texttt{find} functions working in ``any'' monad.
Non-tail recursion is not possible to fuse, return addresses are dynamic.
Tail recursion can return to statically known points.

\subsection{Discussion}

Limitations. We can't put non-value actions into structures, can't accumulate them.

Guarantees/properties. Closure-freedom. No administrative redexes. No boxing in join points.
Only boxing in monadic code comes from ``down''. No code blowup.

\section{Fusion}\label{sec:push-pull-fusion}

Motivation.


\subsection{Push streams}\label{sec:push-streams}

Definition.

\subsection{Pull streams}\label{sec:pull-streams}

Pull streams are definitely not monadic. \texttt{Nat -> Stream a} contains
``infinite'' amount of code internally.

Pull streams are also not selective functors.

We do have monadic binding for lifted types, plus ``case'' matching
on arbitrary object values! This is practically almost as good as
having unlimited monadic bind! We need to assume a ``non-dependency axiom'',
that any $f : \Lift A \to \msf{ValTy}$ must be constant.

\todo{Validate non-dependency in the psh model!}
\todo{Add meta-identity type to the psh model}

\interlinepenalty=10000
\bibliography{references}

\end{document}
\endinput
