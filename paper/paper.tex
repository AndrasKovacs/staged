%% build: latexmk -pdf -pvc paper.tex

\documentclass[acmsmall]{acmart}
\raggedbottom

%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a JOURNAL article.
\acmJournal{JACM}
\acmVolume{37}
\acmNumber{4}
\acmArticle{111}
\acmMonth{8}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%% --------------------------------------------------------------------------------

\usepackage{xcolor}
\usepackage{mathpartir}
\usepackage{todonotes}
\presetkeys{todonotes}{inline}{}
\usepackage{scalerel}
%% \usepackage{amssymb}

\newcommand{\mit}[1]{\mathit{#1}}
\newcommand{\msf}[1]{\mathsf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}

\newcommand{\Lift}{{\Uparrow}}
\newcommand{\spl}{{\sim}}
\newcommand{\qut}[1]{\langle #1\rangle}

\renewcommand{\U}{\msf{U}}
\newcommand{\Con}{\msf{Con}}
\newcommand{\Sub}{\msf{Sub}}
\newcommand{\Ty}{\msf{Ty}}
\newcommand{\Tm}{\msf{Tm}}

\newcommand{\Bool}{\msf{Bool}}
\newcommand{\true}{\msf{true}}
\newcommand{\false}{\msf{false}}
\newcommand{\List}{\msf{List}}
\newcommand{\nil}{\msf{nil}}
\newcommand{\cons}{\msf{cons}}
\newcommand{\Nat}{\msf{Nat}}
\newcommand{\zero}{\msf{zero}}
\newcommand{\suc}{\msf{suc}}
\renewcommand{\tt}{\msf{tt}}
\newcommand{\fst}{\msf{fst}}
\newcommand{\snd}{\msf{snd}}
\newcommand{\mylet}{\msf{let}}
\newcommand{\emptycon}{\scaleobj{.75}\bullet}

\newcommand{\blank}{{\mathord{\hspace{1pt}\text{--}\hspace{1pt}}}}

\theoremstyle{remark}
\newtheorem{notation}{Notation}


%% --------------------------------------------------------------------------------

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

\title{Staged Compilation With Two-Level Type Theory}

%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{András Kovács}
\email{kovacsandras@inf.elte.hu}
\orcid{0000-0002-6375-9781}
\affiliation{%
  \institution{Eötvös Loránd University}
  \country{Hungary}
  \city{Budapest}
}

\begin{abstract}
  The aim of staged compilation is to enable metaprogramming in a way such that
  we have guarantees about the well-formedness of code output, and we can also
  mix together object-level and meta-level code in a concise and convenient
  manner. In this work, we observe that two-level type theory (2LTT), a system
  originally devised for the purpose of synthetic homotopy theory, also serves
  as a system for staged compilation dependent types. 2LTT has numerous good
  properties for this use case: it has a concise specification, well-developed
  algebraic and categorical model theory, and it supports a wide range of
  language features both at the object and the meta level. First, we give an
  overview of 2LTT's features and applications in staging. Then, we present a
  staging algorithm and provide a proof of correctness. Our algorithm is
  ``staging-by-evaluation'', analogously to the technique of
  normalization-by-evaluation, in that staging is given by the evaluation of
  2LTT syntax in a semantic domain. Staging together with its correctness
  constitutes a proof of strong conservativity of 2LLT over the object
  theory. To our knowledge, this is the first system for staged compilation which
  supports full dependent types and unrestricted staging for types.
\end{abstract}

\begin{CCSXML}
\end{CCSXML}

\keywords{type theory, two-level type theory, staged compilation}
\maketitle

\section{Introduction}

The purpose of staged compilation is to write code-generating programs in a
safe, ergonomic and expressive way. It is always possible to do ad-hoc code
generation, by simply manipulating strings or syntax trees in a sufficiently
expressive programming language. However, these approaches tend to suffer from
verbosity, non-reusability and lack of safety. In staged compilation, there are
certain \emph{restrictions} on which metaprograms are expressible. Usually,
staged systems enforce typing disciple, prohibit arbitrary manipulation of
object-level scopes, and often they also prohibit accessing the internal
structure of object expressions. On the other hand, we get \emph{guarantees}
about the well-scoping or well-typing of the code output, and we are also able
to use concise syntax for embedding object-level code.

\emph{Two-level type theory}, or 2LTT in short, was described by Annekov,
Capriotti, Kraus and Sattler \cite{twolevel}, building on ideas from Vladimir
Voevodsky \cite{hts}. The motivation was to allow convenient metatheoretical
reasoning about a certain mathematical language (homotopy type theory), and to
enable concise and modular ways to extend the language with axioms.

It turns out that metamathematical convenience closely corresponds to to
metaprogramming convenience: 2LTT can be directly and effectively employed
in staged compilation. Moreover, semantic ideas underlying 2LTT are also
directly applicable to the theory of staging.

\subsection{Contributions}

\begin{itemize}
  \item In \ref{TODO} we present an informal syntax of two-level type theory, a
    dependent type theory with staging features. We look at basic use-cases
    involving inlining control, partial evaluation and fusion optimizations. We
    also describe several feature variations, enabling applications in
    monomorphization and memory layout control.
  \item In \ref{TODO}, following \cite{twolevel}, we present a formal syntax of
    2LTT and the object theory (the target theory of code generation). We recall
    the standard presheaf model of 2LTT, which lies over the syntactic category
    of the object theory. We show that the evaluation of 2LTT syntax in the presheaf
    model yields a staging algorithm.
  \item In \ref{TODO} we show correctness of staging, consisting of
    \begin{itemize}
    \item \emph{Stability:} staging the output of staging has no action.
    \item \emph{Soundness:} the output of staging is convertible to the input.
    \item \emph{Completeness:} convertible programs produce convertible staging outputs.
    \end{itemize}
    Staging together with its correctness can be viewed as a \emph{strong
    conservativity} theorem of 2LTT over the object theory. Intuitively, this
    means that the possible object-level constructions in 2LTT are in bijection
    with the constructions in the object theory, and staging witnesses that
    meta-level constructions can be always computed away. This improves on the
    weak notion of conservativity shown in \cite{capriotti2017models} and
    \cite{twolevel}.
  \item To our knowledge, this is the first description of a language which
    supports staging in the presence of full-blown dependent types, with
    universes and large elimination. Moreover, we allow unrestricted staging
    for types, so that types can be computed by metaprograms at compile time.
\end{itemize}

\section{A Tour of Two-Level Type Theory}

In this section, we provide a short overview of 2LTT. We work in the informal
syntax of a dependently typed language which resembles Agda \cite{TODO}. We focus
on examples and informal explanations here; the formal details will be presented
in Section \cite{TODO}.

\begin{notation}
We use the following notations throughout the paper. $(x : A) \to B$ denotes a
dependent function type, where $x$ may occur in $B$. We use $\lambda\,x.\,t$ for
abstraction. A $\Sigma$-type is written as $(x : A) \times B$, with pairing as
$(t,\,u)$, and we may use pattern matching notation on pairs, e.g.\ as in
$\lambda\,(x,\,y).\,t$. The unit type is $\top$ with element $\tt$. We will also
use Agda-style notation for implicit arguments, where $t : \{x : A\} \to B$
implies that the first argument to $t$ is inferred by default, and we can
override this by writing a $t \{u\}$ application. We may also implicitly
quantify over arguments (in the style of Idris and Haskell), for example
when declaring $\mit{id} : A \to A$ with the assumption that $A$ is universally
quantified.
\end{notation}

\subsection{Rules of 2LTT}

\paragraph{Universes} We have universes $\U_{i,j}$, where $i \in \{0,1\}$, and $j \in \mbb{N}$.
The $i$ index denotes stages, where $0$ is the runtime (object-level) stage, and
$1$ is the compile time (meta-level) stage. The $j$ index denotes universe sizes
in the usual sense of type theory. We assume Russell-style universes, with
$\U_{i,j} : \U_{i, j+1}$. However, for the sake of brevity we will usually omit
the $j$ indices in this section, and simply write $\U_0$ or $\U_1$.
\begin{itemize}
\item $\U_0$ can be viewed as the \emph{universe of object-level or runtime types}.
    Each closed type $A : \U_0$ can be staged to an actual type in the object language
    (the language of the staging output).
  \item $\U_1$ can be viewed as the \emph{universe of meta-level or static types}. If we
    have $A : \U_1$, then $A$ is guaranteed to be only present at compile time,
    and will be staged away. Elements $a : A$ are likewise computed away.
\end{itemize}

\paragraph{Type formers} $\U_0$ and $\U_1$ may be closed under arbitrary type formers,
such as functions, $\Sigma$-types, identity types or inductive types in general.
However, all constructors and eliminators in type formers must stay at the same
stage. For example:
\begin{itemize}
  \item Function domain and codomain types must be at the same stage.
  \item If we have $\Nat_0 : \U_0$ for the runtime type of natural numbers,
        we can only map from it to a type in $\U_0$ by recursion or induction.
\end{itemize}
It is not required that we have the \emph{same} type formers at both stages. As we will
see in Section \cite{TODO}, simpler object languages have the advantage that they are
easier to process during downstream compilation.

\paragraph{Moving between stages} At this point, our system is rather limited, since
there is no interaction between the stages. We add such interaction via the follow
three operations.
\begin{itemize}
\item \emph{Lifting:} for $A : \U_0$, we have $\Lift A : \U_1$.  From the
  staging point of view, $\Lift A$ is the type of metaprograms which compute
  to runtime expressions of type $A$.
\item \emph{Quoting:} for $A : \U_0$ and $t : A$, we have $\qut{t} :\,\Lift A$.
  A quoted term $\qut{t}$ represents the metaprogram which immediately computes
  to $t$.
\item \emph{Splicing:} for $A : \U_0$ and $t :\,\Lift A$, we have $\spl t : A$.
  During staging, the metaprogram in the splice is executed, and the resulting
  expression is inserted into the output.
  \begin{notation} Splicing binds stronger than any operation, including function
    application. For instance, $\spl f\,x$ is parsed as $(\spl f)\,x$.
  \end{notation}

\item Quoting and splicing are definitional inverses, i.e.\ we have $\spl\qut{t} = t$ and
  $\qut{\spl t}=t$ as definitional equalities.
\end{itemize}
Note that none of these three operations can be expressed as functions, since
function types cannot cross between stages.

Informally, if we have a closed program $t : A$ with $A : \U_0$, \emph{staging}
means computing all metaprograms and recursively replacing all splices in $t$ and $A$
with the resulting runtime expressions. The rules of 2LTT ensure that this is possible,
and we always get a splice-free runtime program after staging.

\paragraph{Remark}
Why do we use the index $0$ for the runtime stage? The reason is that it is not
difficult to generalize 2LTT to multi-level type theory, by allowing to lift
types from $\U_i$ to $\U_{i+1}$. In the semantics, this can be modeled by
having a 2LTT whose object theory is once again a 2LTT, and doing this in an
iterated fashion. But there must be necessarily a bottom-most object theory;
hence our stage indexing scheme. For now though, we leave the multi-level
generalization to future work.

\begin{notation} We may disambiguate type formers at different stages by using $0$ or $1$
subscripts. For example, $\Nat_1 : \U_1$ is distinguished from $\Nat_0 : \U_0$,
and likewise we may write $\zero_0 : \Nat_0$ and so on. For function and
$\Sigma$ types, the stage is usually easy to infer, so we do not annotate
them. For example, the type $\Nat_0 \to \Nat_0$ must be at the runtime stage,
since the domain and codomain types are at that stage, and we know that the
function type former stays within a single stage. We may also omit stage annotations
from $\lambda$ and pairing.
\end{notation}

\subsection{Staged Programming in 2LTT}

In 2LTT, we may have several different polymorphic identity functions. First, we
consider the usual identity functions at each stage:
\begin{alignat*}{3}
  & \mit{id}_0 : (A : \U_0) \to A \to A\hspace{2em} && \mit{id}_1 : (A : \U_1) \to A \to A\\
  & \mit{id}_0 := \lambda\,A\,x.x       && \mit{id}_1 := \lambda\,A\,x.x
\end{alignat*}
An $\mit{id}_0$ application will simply appear in staging output as it is. In
contrast, $\mit{id}_1$ can be used as a compile-time evaluated function, because
the staging operations allow us to freely apply $\mit{id}_1$ to runtime
arguments. For example, $\mit{id}_1\,(\Lift\,\Bool_0)\,\qut{\true_0}$ has type
$\Lift \Bool_0$, therefore $\spl(\mit{id}_1\,(\Lift\,\Bool_0)\,\qut{\true_0})$
has type $\Bool_0$. We can stage this expression as follows:
\[
\spl(\mit{id}_1\,(\Lift\,\Bool_0)\,\qut{\true_0}) = \spl\qut{\true_0} = \true_0
\]
There is another identity function, which computes at compile time, but which
can be only used on runtime arguments:
\begin{alignat*}{3}
  & \mit{id_\Lift} : (A : \Lift\U_0) \to \Lift\,\spl A \to \Lift\,\spl A\\
  & \mit{id_\Lift} := \lambda\,A\,x.x
\end{alignat*}
Note that since $A : \Lift\U_0$, we have $\spl A : \U_0$, hence $\Lift\,\spl A
: \U_1$.  Also, $\Lift\U_0 : \U_1$, so all function domain and codomain types in
the type of $\mit{id_\Lift}$ are at the same stage. Now, we may write
$\spl(\mit{id_\Lift}\,\qut{\Bool_0}\,\qut{\true_0})$ for a term which is staged
to $\true_0$. In this specific case $\mit{id_\Lift}$ has no practical advantage
over $\mit{id}_1$, but in some cases we really have to quantify over
$\Lift\U_0$. This brings us the next example.

Assume $\List_0 : \U_0 \to \U_0$ with $\nil_0 : (A : \U_0) \to \List_0\,A$,
$\cons_0 : (A : \U_0) \to A \to \List_0\,A$ and $\msf{foldr}_0 : (A\,B : \U_0)
\to (A \to B \to B) \to B \to \List_0\,A \to B$. We define a map function which
``inlines'' its function argument:
\begin{alignat*}{3}
  & \mit{map} : (A\,B : \Lift\U_0) \to (\Lift\,\spl A \to \Lift\,\spl B)
      \to \Lift(\List_0\,\spl A) \to \Lift(\List_0\,\spl B)\\
  & \mit{map} := \lambda\,A\,B\,f\,\mit{as}.\,
      \qut{\msf{foldr}_0\,
        \spl A\,\spl B\,
        (\lambda\,a\,\mit{bs}.\, \cons_0\,\spl B\,\spl(f\,\qut{a})\,\mit{bs})\,
        (\nil_0\,\spl B)\,
        \spl as
        }
\end{alignat*}
This $\mit{map}$ function works with quantification over $\Lift \U_0$ but not
over $\U_1$, because $\List_0$ expects type parameters in $\U_0$, and there is
no generic way to convert from $\U_1$ to $\U_0$. Now, assuming
$\blank\!+_0\!\blank : \Nat_0 \to \Nat_0 \to \Nat_0$ and $\mit{ns} :
\List_0\,\Nat_0$, we have the following staging behavior:
\begin{alignat*}{3}
  & &&\spl(\mit{map}\,\qut{\Nat_0}\,\qut{\Nat_0}\,(\lambda\,n.\,\qut{\spl n +_0 10})\,\qut{\mit{ns}})\\
  & =\hspace{1em}&&\spl\qut{\msf{foldr}_0\,
        \spl \qut{\Nat_0}\,\spl \qut{\Nat_0}\,
        (\lambda\,a\,\mit{bs}.\, \cons_0\,\spl B\,\spl\qut{\spl\qut{a} +_0 10}\,\mit{bs})\,
        (\nil_0\,\spl \qut{\Nat_0})\,
        \spl\qut{\mit{ns}}}\\
  & =\hspace{1em} &&\msf{foldr_0}\,\Nat_0\,\Nat_0\,\,(\lambda\,a\,bs.\,a +_0 10)\,(\nil_0\,\Nat_0)\,\mit{ns}
\end{alignat*}

By using meta-level functions and lifted types, we already have control over
inlining. However, if we want to do more complicated meta-level computation, it
is convenient to use recursion or induction on meta-level type formers. A
classic example in staged compilation is the power function for natural numbers,
which evaluates the exponent at compile time. We assume the iterator function
$\msf{iter_1} : \{A : \U_1\} \to \Nat_1 \to (A \to A) \to A \to A$, and runtime
multiplication as $\blank\!*_0\!\blank$.
\begin{alignat*}{3}
  &\mit{exp} : \Nat_1 \to \Lift \Nat_0 \to \Lift \Nat_0 \\
  &\mit{exp} := \lambda\,x\,y.\,
  \msf{iter}_1\,x\,(\lambda\,n.\,\qut{\spl y *_0 \spl n})\,\qut{1}
\end{alignat*}
Now, $\spl(\mit{exp}\,3\,\qut{n})$ stages to $n *_0 n *_0 n *_0 1$ by the computation rules
of $\msf{iter_1}$ and the staging operations.

We can also stage \emph{types}. Below, we use iteration to compute the type of
vectors with static length, as a nested pair type.
\begin{alignat*}{3}
  &\mit{Vec} : \Nat_1 \to \Lift \U_0 \to \Lift \U_0\\
  &\mit{Vec} := \lambda\,n\,A.\,\msf{iter}_1\,n\,(\lambda\,B.\,\qut{\spl A \times \spl B})\,\qut{\top_0}
\end{alignat*}
With this definition, $\spl(\mit{Vec}\,3\,\qut{\Nat_0})$ stages to $\Nat_0
\times (\Nat_0 \times (\Nat_0 \times \top_0))$. Now, we can use \emph{induction}
on $\Nat_1$ to implement a map function. For readability, we use an Agda-style
pattern matching definition below (instead of the elimination principle).
\begin{alignat*}{6}
  &\hspace{-3em}\rlap{$\mit{map} : (n : \Nat_1) \to (\Lift\,\spl A \to \Lift\,\spl B) \to \Lift(\mit{Vec}\,n\,A) \to \Lift(\mit{Vec}\,n\,B)$}\\
  &\hspace{-3em}\mit{map}\,&&\zero_1      && f\,&&\mit{as} := \qut{\tt_0}\\
  &\hspace{-3em}\mit{map}\,&&(\suc_1\,n)\,&& f\,&&\mit{as} :=
     \qut{(\spl(f\,\qut{\fst_0\,\spl\mit{as}}),\,\mit{map}\,n\,f\,\qut{\snd_0\,\spl \mit{as}})}
\end{alignat*}
This definition inlines the mapping function for each projected element of the
vector. For instance, staging $\spl(\mit{map}\,2\,(\lambda\,n.\,\qut{\spl n +_0
  10})\,\qut{\mit{ns}})$ yields $(\fst_0\,\mit{ns} +_0
10,\,(\fst_0(\snd_0\,\mit{ns}) +_0 10,\,\tt_0))$. Sometimes, we do not want to
duplicate the code of the mapping function. In such cases, we can use
\emph{let-insertion} \cite{TODO}, a standard technique in staged compilation. If
we bind a runtime expression to a runtime variable, and only use that variable
in subsequent staging, only the variable itself can be duplicated, as an
expression. One solution is to do an ad-hoc let-insertion:
\begin{alignat*}{6}
  &   && \mylet_0\,f := \lambda\,n.\, n +_0 10\,\,\msf{in}\,\,
         \spl(\mit{map}\,2\,(\lambda\,n.\,\qut{f\,\spl n})\,\qut{\mit{ns}}) \\
  & =\,\,&&  \mylet_0\,f := \lambda\,n.\, n +_0 10\,\,\msf{in}\,\,
          (f\,(\fst_0\,\mit{ns}),\,(f\,(\fst_0(\snd_0\,\mit{ns})),\,\tt_0))
\end{alignat*}
 Alternatively, we can define $\mit{map}$ so that it performs let-insertion, and
 we can switch between the two versions as needed.

More generally, we are free to use dependent types at the meta-level, so we can
reproduce more complicated staging examples. Any well-typed interpreter can be
rephrased as a \emph{partial evaluator}, as long as we have sufficient type
formers. For instance, we may write a partial evaluator for a simply typed
lambda calculus. We sketch the implementation in the following. First, we
inductively define contexts, types and terms:
\begin{alignat*}{6}
  & \Ty : \U_1  \hspace{2em} \Con : \U_1 \hspace{2em} \Tm : \Con \to \Ty \to \U_1
\end{alignat*}
Then we define the interpretation functions:
\begin{alignat*}{6}
  & \msf{EvalTy}  &&: \Ty \to \Lift \U_0 \\
  & \msf{EvalCon} &&: \Con \to \U_1 \\
  & \msf{EvalTm}  &&: \Tm\,\Gamma\,A \to \msf{EvalCon}\,\Gamma \to \Lift\,\spl(\msf{EvalTy}\,A)
\end{alignat*}
Types are necessarily computed to runtime types, since we can only stage to such types.
Contexts are computed as follows:
\begin{alignat*}{4}
  &\msf{EvalCon}\,\,\msf{empty}                &&:= \top_1 \\
  &\msf{EvalCon}\,\,(\msf{extend}\,\Gamma\,A) &&:= \msf{EvalCon}\,\Gamma \times (\Lift \spl(\msf{EvalTy}\,A))
\end{alignat*}
This is an nice example for the usage of \emph{partially static
data}\cite{TODO}: semantic contexts are \emph{static} lists storing
\emph{runtime} expressions. This allows us to completely eliminate environment
lookups in the staging output: an embedded lambda expression is staged to the
corresponding lambda expression in the runtime language. This is similar to the
partial evaluator presented in Idris 1 \cite{TODO}. However, in contrast to
2LTT, Idris 1 does not provide a formal guarantee that partial evaluation does
not get stuck.

\subsection{Properties of Lifting}

preservation properties
\\\\
stage inference

\subsection{Restricting the Object Language}

monomorphization
\\\\
memory layout control
\\\\
typed closures

\subsection{Fusion}
2LTT is also a natural setting for a wide range of \emph{fusion
optimizations}. We only describe here a simple example, \emph{foldr-build
fusion} for lists, which is notably used in GHC Haskell \cite{TODO}. The idea is
the following: we want to eliminate intermediate lists, e.g.\ fuse repeated
mapping to a single traversal. For this, we exploit that there is an isomorphic
\emph{meta-level} representation for runtime lists which supports more
definitional equations. Starting from $\Lift (\List_0\,A)$, we can use
Böhm-Berarducci encoding under the lifting to get
\[ \Lift((L : \U_0) \to (A \to L \to L) \to L \to L) \]
However, $\Lift$ preserves function types, so the above is definitionally
isomorphic to
\[ (L : \Lift\,U_0) \to (\Lift\,A \to \Lift\,\spl L \to \Lift\,\spl L)
\to \Lift\,\spl L \to \Lift\,\spl L. \] Now, we may abbreviate the above type as
$\msf{BBList}\,A$. We write fusible functions on $\msf{BBList}\,A$, and when we
want to fuse a definition, we convert from $\Lift\,(\List_0\,A)$ to
$\msf{BBList}\,A$, apply operations on that representation, then convert back in
the end.

Now, in 2LTT it is not provable that Böhm-Berarducci encoding is an isomorphism \cite{TODO},
so it certainly does not hold that back-and forth conversion between the two
representations is definitionally the identity function. In GHC Haskell, this
equality is added as a \emph{rewrite rule}. This makes it possible to hide the
back-and-forth conversions from library users, since inverse conversions will
hopefully cancel out and cause no additional overhead. A similar mechanism could be
used in 2LTT as well. However, such implicit conversions are not used in most
languages which support fusion. For example, iterators in the Rust language
\cite{TODO}, which use a form of stream fusion, require explicit conversion to
iterators.

We may compare GHC and 2LTT with respect to the implementation of fusion. In
2LTT, fusion happens through meta-level $\beta$-reduction, which is formally
guaranteed to go through, and which can be also computed very efficiently. In
GHC, all of the necessary computation is realized by rewrite rules and
general-purpose optimization passes. This is in practice very fragile and
non-composable. It requires carefully tuning every individual collection of
rewrite rules, and also ordering rule applications in specific ways, while
keeping details of the compiler optimization passes in mind. And when fusion
fails to go through, it is usually a performance \emph{pessimization}.

















\subsection{Properties of Lifting}




















































%% we shall work in the syntax of a dependently typed language
%% which resembles Agda.







\subsection{Informal Syntax}

\section{Variations \& Applications}

\subsection{Fusion}

\subsection{Monomorphization}

\subsection{Levity Polymorphism}

\subsection{Typed Closures}

\section{Formal Syntax \& Models}

\subsection{Metatheory}
\subsection{Models}

\section{Staging by Evaluation}

\subsection{Presheaf Model of 2LTT}

\subsection{Closed staging}
\subsection{Yoneda, representability, intensional analysis}

\section{Stability}

\subsection{Open staging}

\section{Soundness}

\subsection{Internal Language \& Features}
\subsection{The Logical Relation}
\subsection{Externalization \& Soundness}

\section{Related Work}

Igarashi, Kiselyov et al, MetaML, MetaOCaml, Carette, TH, Scala ppl (?)
PE lit ?
2LTT, Voevodsky,

\section{Future Work \& Conclusions}


\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
\endinput
